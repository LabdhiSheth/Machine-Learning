{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Gaussian Naive Bayes classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "We have 150 samples\n",
      "With 4 features each\n",
      "\n",
      "75 samples in the training set\n",
      "75 samples in the test set\n",
      "3 class labels\n",
      "\n",
      "[[5.024 3.48  1.456 0.228]\n",
      " [5.992 2.776 4.308 1.352]\n",
      " [6.504 2.936 5.564 2.076]]\n",
      "\n",
      "[[0.38291513 0.31874755 0.20214846 0.07756288]\n",
      " [0.5447348  0.32897416 0.4698255  0.18998947]\n",
      " [0.59091793 0.28125433 0.53432574 0.27317394]]\n"
     ]
    }
   ],
   "source": [
    "#loading the dataset\n",
    "X,y = load_iris(return_X_y=True)\n",
    "\n",
    "n,d = X.shape\n",
    "print()\n",
    "print (\"We have {} samples\".format(n))\n",
    "print (\"With {} features each\".format(d))\n",
    "\n",
    "#dividing into test and train dataset\n",
    "X_train = X[range(0,150,2),:]\n",
    "y_train = y[range(0,150,2)]\n",
    "\n",
    "X_test = X[range(1,150,2),:]\n",
    "y_test = y[range(1,150,2)]\n",
    "\n",
    "n_train = len(X_train)\n",
    "n_test = len(X_test)\n",
    "print()\n",
    "print (\"{} samples in the training set\".format(n_train))\n",
    "print (\"{} samples in the test set\".format(n_test))\n",
    "\n",
    "iris_dataset = load_iris()\n",
    "Cn = len(iris_dataset.target_names)\n",
    "print(\"{} class labels\".format(Cn))\n",
    "\n",
    "#mean matrix\n",
    "mu_mat = np.zeros((Cn,d), dtype=float)\n",
    "\n",
    "#stddev matrix\n",
    "sig_mat = np.zeros((Cn,d), dtype=float)\n",
    "\n",
    "\n",
    "for i in range(0,Cn):\n",
    "    mu_mat[i] = X_train[y_train==i].mean(axis=0)\n",
    "    sig_mat[i] = X_train[y_train==i].std(axis=0)\n",
    "\n",
    "print()\n",
    "print(mu_mat)\n",
    "print()\n",
    "print(sig_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Likelihood: [0.33333333 0.33333333 0.33333333]\n",
      "\n",
      "Probability that the Model predicts the correct class label:\n",
      "0.96\n"
     ]
    }
   ],
   "source": [
    "epsilon = 0.01\n",
    "\n",
    "# class_likelihood (Prior)\n",
    "class_likelihood = np.zeros(Cn, dtype=float)\n",
    "for i in range(0,Cn):\n",
    "    class_likelihood[i] = (y_train==i).sum()/n_train\n",
    "\n",
    "print(\"Likelihood:\",class_likelihood)\n",
    "print()\n",
    "\n",
    "# Class_given_data (Posterior)\n",
    "class_given_data_mat = np.zeros((n_test,Cn), dtype=float)\n",
    "for i in range(0,n_test):\n",
    "    for k in range(0,Cn):\n",
    "        class_given_data = np.log(class_likelihood[k])\n",
    "        for j in range(0,d):\n",
    "            class_given_data = class_given_data + np.log(sp.stats.norm.pdf(X_test[i,j],mu_mat[k,j],sig_mat[k,j])*2*epsilon)\n",
    "        class_given_data_mat[i,k] = class_given_data \n",
    "\n",
    "print (\"Probability that the Model predicts the correct class label:\")\n",
    "print ((class_given_data_mat.argmax(axis=1)==y_test).sum()/n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial Naive Bayes classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction :- \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 2 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 1 1 1 2 2 2 2 2 2 2\n",
      " 2]\n",
      "\n",
      "Accuracy score :-\n",
      " 0.9466666666666667\n",
      "\n",
      "Classification report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        25\n",
      "           1       0.89      0.96      0.92        25\n",
      "           2       0.96      0.88      0.92        25\n",
      "\n",
      "    accuracy                           0.95        75\n",
      "   macro avg       0.95      0.95      0.95        75\n",
      "weighted avg       0.95      0.95      0.95        75\n",
      "\n",
      "\n",
      "Confusion Matrix :-\n",
      " [[25  0  0]\n",
      " [ 0 24  1]\n",
      " [ 0  3 22]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "\n",
    "MNBclf = MultinomialNB()\n",
    "MNBclf.fit(X, y)\n",
    "prediction = MNBclf.predict(X_test)\n",
    "print(\"Prediction :- \\n\",prediction)\n",
    "\n",
    "print(\"\\nAccuracy score :-\\n\",metrics.accuracy_score(y_test, prediction, normalize= True))\n",
    "\n",
    "print(\"\\nClassification report :- \\n\",metrics.classification_report(y_test, prediction))\n",
    "\n",
    "print(\"\\nConfusion Matrix :-\\n\",metrics.confusion_matrix(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bernoulli Naive Bayes classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction :- \n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "\n",
      "Accuracy score :-\n",
      " 0.3333333333333333\n",
      "\n",
      "Classification report :- \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      1.00      0.50        25\n",
      "           1       0.00      0.00      0.00        25\n",
      "           2       0.00      0.00      0.00        25\n",
      "\n",
      "    accuracy                           0.33        75\n",
      "   macro avg       0.11      0.33      0.17        75\n",
      "weighted avg       0.11      0.33      0.17        75\n",
      "\n",
      "\n",
      "Confusion Matrix :-\n",
      " [[25  0  0]\n",
      " [25  0  0]\n",
      " [25  0  0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\labdh\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "Bnclf = BernoulliNB()\n",
    "Bnclf.fit(X, y)\n",
    "prediction = Bnclf.predict(X_test)\n",
    "print(\"Prediction :- \\n\",prediction)\n",
    "\n",
    "print(\"\\nAccuracy score :-\\n\",metrics.accuracy_score(y_test, prediction, normalize= True))\n",
    "\n",
    "print(\"\\nClassification report :- \\n\",metrics.classification_report(y_test, prediction))\n",
    "\n",
    "print(\"\\nConfusion Matrix :-\\n\",metrics.confusion_matrix(y_test,prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
